# 模型参数

**温度**

浮点类型，每次可调整0.01，最大1.99。

核采样阈值。用于决定结果随机性，取值越高随机性越强即相同的问题得到的不同答案的可能性越高。

**Top P**

浮点类型，每次可调整0.01，最大1，最小0.01。

生成过程中核采样方法概率阈值。取值越大，生成的随机性越高；取值越小，生成的确定性越高。

**存在惩罚**

浮点类型，每次可调整0.01，最大2，最小-2。

用于控制模型生成时的重复度。提高此项可以降低模型生成的重复度。



# 推理引擎

类比web应用，写好的代码不能直接运行，需要借助nginx部署到web服务器上。而训练得到的模型文件类比写好的代码，需要借助推理引擎运行。



# 强化学习RL（Reinforcement learing）

DQN（Deep Q-Networks）

TRPO（Trust Region Policy Optmization）

近端策略优化PPO（Proximal Policy Optimization）









